# -*- coding: utf-8 -*-
"""Copy of kmeansfromscratch

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MVtcCL9Ut0TXZM1vgcjKi-_H3d40UyVk
"""

import numpy as np
import pandas as pd
from scipy.spatial.distance import cdist
from sklearn.datasets import load_digits
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.metrics import pairwise_distances_argmin

#Function to implement steps given in previous section
def kmeans(x,k, no_of_iterations):
    idx = np.random.choice(len(x), k, replace=False)
    print(idx)
    #Randomly choosing Centroids
    centroids = x[idx, :] #Step 1
    print(centroids)

    #finding the distance between centroids and all the data points
    distances = cdist(x, centroids ,'euclidean') #Step 2
    print(distances)

    #Centroid with the minimum Distance
    points = np.array([np.argmin(i) for i in distances]) #Step 3

    #Repeating the above steps for a defined number of iterations
    #Step 4
    for _ in range(no_of_iterations):
        centroids = []
        for idx in range(k):
            #Updating Centroids by taking mean of Cluster it belongs to
            temp_cent = x[points==idx].mean(axis=0)
            centroids.append(temp_cent)

        centroids = np.vstack(centroids) #Updated Centroids
        distances = cdist(x, centroids ,'euclidean')
        points = np.array([np.argmin(i) for i in distances])

    return points
    #Load Data
data = load_digits().data
pca = PCA(2)

#Transform the data
df = pca.fit_transform(data)

#Applying our function
label = kmeans(df,10,1000)

#Visualize the results

u_labels = np.unique(label)
for i in u_labels:
    plt.scatter(df[label == i , 0] , df[label == i , 1] , label = i)
plt.legend()
plt.show()

n_cluster = 2
x = np.array([[1.2, 1],[2, 1.5],[3, 4.5],[5.6, 3],[2.4, 1.5],[6.7, 9],[4,2],[6,7.4],[8.7, 9],[4,7],[3,7],[2,6],[4,9],[4,5]])
x.shape

plt.scatter(x[:,0],x[:,1], s = 100)
plt.show()

rng = np.random.RandomState(2)
l = rng.permutation(x.shape[0])[:n_cluster]
print('Permutations', l)

centers = x[l]
print("Centers", centers)

while True:
  labels = pairwise_distances_argmin(x, centers)
  print("Calculated distance", labels)
  new_centers = np.array([x[labels == l].mean(0) for l in range(n_cluster)])
  print("Updated centers", new_centers)
  if np.all(centers == new_centers):
    break
  centers = new_centers
  print(centers)
  print()

plt.scatter(x[:,0], x[:,1], s = 100, c = labels,  cmap = 'viridis' )
plt.scatter(centers[:,0], centers[:,1], s = 100, c = 'red')
plt.title("KMeans clustering")
plt.show()

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters = 2, random_state = 0, n_init = 'auto')
kmeans.fit(x)
kmeans
a = kmeans.labels_

kmeans.predict([[0, 0]])

wcss = []
for l in range(1,5):
  kmeans = KMeans(n_clusters = l)
  kmeans.fit(x)
  wcss.append(kmeans.inertia_)
plt.plot(range(1,5), wcss)
plt.xlabel('Number of cluster')
plt.ylabel('WCSS')
plt.show()

y = np.array([[0],[0],[0],[0],[0],[0],[0],[1],[1],[1],[1],[1],[1],[1]])
y.shape

plt.scatter(x[:,0], x[:, 1], c = y, s = 100, cmap = 'viridis')
plt.scatter(3,3,s = 100)
plt.title('KNN')
plt.show()

a = []
p = [3,3]
for i in x:
  s = np.sqrt((i[0]-p[0])**2 + (i[1]-p[1])**2)
  print(s)
  a.append(s)

df = pd.DataFrame()
df['x'] = x.tolist()
df['y'] = y
df['Distance'] = a

df

df.sort_values('Distance', inplace = True)
df

k = 3
df['y'][:3].value_counts()

x_shape = x.shape
y_shape = y.shape

print(f"Shape of x: {x_shape}")
print(f"Shape of y: {y_shape}")

if x_shape[0] != y_shape[0]:
    raise ValueError("Number of samples in x and y must be the same.")

from sklearn.neighbors import KNeighborsClassifier
k = KNeighborsClassifier(n_neighbors = 3)
k.fit(x, y)

print(k.predict([[3,3]]))

